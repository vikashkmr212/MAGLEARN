{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44636bd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad47294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.utils import resample\n",
    "import joblib\n",
    "\n",
    "\n",
    "sns.set(context=\"notebook\", style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd79b6ba",
   "metadata": {},
   "source": [
    "### Config & Feature Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv = \"core_top_data.csv\"     # training data file\n",
    "artifacts_dir = \"artifacts\"\n",
    "os.makedirs(artifacts_dir, exist_ok=True)\n",
    "\n",
    "pipeline_path = os.path.join(artifacts_dir, \"maglearn_residual_pipeline.joblib\")\n",
    "paramT_csv_path = os.path.join(artifacts_dir, \"core_top_with_paramT.csv\")\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "target_col = \"t_annual\"\n",
    "num_features_residual = [\"mgca\", \"omega_inv_sq\"]      \n",
    "cat_features_residual = [\"species\", \"clean_method\"]\n",
    "\n",
    "\n",
    "PARAM_COEFFS = dict(a_mean=0.036, a_std=0.006,\n",
    "                    b_mean=0.061, b_std=0.005,\n",
    "                    c_mean=-0.73, c_std=0.07,\n",
    "                    d_mean=0.0,   d_std=0.0)\n",
    "\n",
    "N_MC = 1_000_000 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c16eaeb",
   "metadata": {},
   "source": [
    "### Parametric T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab25c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_parametric_T(df, coeffs, n_mc=1_000_000, seed=42):\n",
    "    \"\"\"\n",
    "    Vectorized per-row Monte Carlo for parametric T:\n",
    "      Mg/Ca = exp(a*(S-35) + b*T + c*(pH-8) + d)\n",
    "      => T = [ln(MgCa) - a*(S-35) - c*(pH-8) - d] / b\n",
    "    Returns: mean (np.ndarray), std (np.ndarray)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    a_s = rng.normal(coeffs[\"a_mean\"], coeffs[\"a_std\"], n_mc)\n",
    "    b_s = rng.normal(coeffs[\"b_mean\"], coeffs[\"b_std\"], n_mc)\n",
    "    c_s = rng.normal(coeffs[\"c_mean\"], coeffs[\"c_std\"], n_mc)\n",
    "    d_s = rng.normal(coeffs[\"d_mean\"], coeffs[\"d_std\"], n_mc)\n",
    "\n",
    "    means = np.empty(len(df), dtype=float)\n",
    "    stds  = np.empty(len(df), dtype=float)\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        mgca = row[\"mgca\"]\n",
    "        S    = row[\"s_annual\"]\n",
    "        pH   = row[\"pH\"]\n",
    "\n",
    "        T_samples = (np.log(mgca)\n",
    "                     - a_s * (S - 35.0)\n",
    "                     - c_s * (pH - 8.0)\n",
    "                     - d_s) / b_s\n",
    "\n",
    "        means[i] = T_samples.mean()\n",
    "        stds[i]  = T_samples.std(ddof=0)\n",
    "\n",
    "    return means, stds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce0aaa7",
   "metadata": {},
   "source": [
    "### Custom Ensemble (Bootstrap Averaging of Base Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cc6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEnsembleRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Bootstraps the training set n_bootstrap times.\n",
    "    \"\"\"\n",
    "    def __init__(self, models, n_bootstrap=500, random_state=42, save_bootstrap_predictions=False, bootstrap_csv_path=None):\n",
    "        self.models = models\n",
    "        self.n_bootstrap = n_bootstrap\n",
    "        self.random_state = random_state\n",
    "        self.save_bootstrap_predictions = save_bootstrap_predictions\n",
    "        self.bootstrap_csv_path = bootstrap_csv_path\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = []\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "\n",
    "        for _ in tqdm(range(self.n_bootstrap), desc=\"Training\"):\n",
    "           \n",
    "            X_b, y_b = resample(X, y, random_state=rng.randint(0, 1_000_000_000))\n",
    "            fitted = [clone(m).fit(X_b, y_b) for m in self.models]\n",
    "            self.models_.append(fitted)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        all_preds = []\n",
    "        for fitted in tqdm(self.models_, desc=\"Predicting\"):\n",
    "            preds = np.column_stack([m.predict(X) for m in fitted]) \n",
    "            mean_per_boot = preds.mean(axis=1)                        \n",
    "            all_preds.append(mean_per_boot)\n",
    "\n",
    "        all_preds = np.vstack(all_preds)                \n",
    "        mean_pred = all_preds.mean(axis=0)              \n",
    "        sigma     = all_preds.std(axis=0)               \n",
    "        lower     = mean_pred - sigma\n",
    "        upper     = mean_pred + sigma\n",
    "\n",
    "        if self.save_bootstrap_predictions and self.bootstrap_csv_path:\n",
    "            pd.DataFrame(all_preds.T,\n",
    "                         columns=[f\"bootstrap_{i+1}\" for i in range(self.n_bootstrap)]\n",
    "                        ).to_csv(self.bootstrap_csv_path, index=False)\n",
    "\n",
    "        return mean_pred, sigma, lower, upper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ea579",
   "metadata": {},
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac82b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(training_csv)\n",
    "\n",
    "required_cols = {\"mgca\", \"omega_inv_sq\", \"s_annual\", \"pH\", \"t_annual\", \"species\", \"clean_method\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "assert not missing, f\"Missing required columns: {missing}\"\n",
    "\n",
    "\n",
    "assert (df[\"mgca\"] > 0).all(), \"Non-positive mgca values detected.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af40e6",
   "metadata": {},
   "source": [
    "### Box-plots of Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afabd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"mgca\", \"omega_inv_sq\", \"s_annual\", \"pH\", \"t_annual\"]\n",
    "\n",
    "\n",
    "melted = df[num_cols].melt(var_name=\"feature\", value_name=\"value\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = sns.boxplot(data=melted, x=\"feature\", y=\"value\")\n",
    "ax.set_title(\"Box-plots of Numeric Features (Training)\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.tick_params(axis=\"x\", rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14098733",
   "metadata": {},
   "source": [
    "### Compute Parametric T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_T, param_T_unc = compute_parametric_T(df, PARAM_COEFFS, n_mc=N_MC, seed=RANDOM_STATE)\n",
    "\n",
    "df[\"param_T\"] = param_T\n",
    "df[\"param_T_uncertainty\"] = param_T_unc\n",
    "\n",
    "\n",
    "\n",
    "residual = df[target_col] - param_T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55875f",
   "metadata": {},
   "source": [
    "### Train/Test Split & Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[num_features_residual + cat_features_residual]\n",
    "y = residual\n",
    "param_T_all = param_T  \n",
    "\n",
    "X_train, X_test, y_train_res, y_test_res, param_T_train, param_T_test = train_test_split(\n",
    "    X, y, param_T_all, test_size=0.30, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_features_residual),\n",
    "        (\"cat\", OrdinalEncoder(),  cat_features_residual)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8253496",
   "metadata": {},
   "source": [
    "### Define Ensemble Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200, max_features=\"sqrt\", max_depth=20,\n",
    "    min_samples_split=2, min_samples_leaf=1, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "gbr = GradientBoostingRegressor(\n",
    "    learning_rate=0.1, max_depth=4, max_features=\"sqrt\", min_samples_split=2,\n",
    "    min_samples_leaf=1, n_estimators=200, subsample=0.9, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "svr = SVR(C=100, degree=2, epsilon=0.1, gamma=\"scale\", kernel=\"rbf\")\n",
    "\n",
    "ensemble = CustomEnsembleRegressor(\n",
    "    models=[rf, gbr, svr],\n",
    "    n_bootstrap=500,\n",
    "    random_state=RANDOM_STATE,\n",
    "    save_bootstrap_predictions=False, \n",
    "    bootstrap_csv_path=os.path.join(artifacts_dir, \"bootstrap_predictions.csv\")\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"ensemble\", ensemble)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69817fd0",
   "metadata": {},
   "source": [
    "### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf0e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90eb146",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr_res_pred, ytr_sigma, ytr_low, ytr_up = pipeline.predict(X_train)\n",
    "yte_res_pred, yte_sigma, yte_low, yte_up = pipeline.predict(X_test)\n",
    "\n",
    "y_train_final = param_T_train + ytr_res_pred\n",
    "y_test_final  = param_T_test  + yte_res_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0523943d",
   "metadata": {},
   "source": [
    "###  Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46287b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = np.sqrt(mean_squared_error(param_T_train + y_train_res, y_train_final))\n",
    "r2_train   = r2_score(param_T_train + y_train_res, y_train_final)\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(param_T_test + y_test_res, y_test_final))\n",
    "r2_test   = r2_score(param_T_test + y_test_res, y_test_final)\n",
    "\n",
    "print(f\"Training RMSE: {rmse_train:.3f}\")\n",
    "print(f\"Training R²:   {r2_train:.3f}\")\n",
    "print(f\"Test RMSE:     {rmse_test:.3f}\")\n",
    "print(f\"Test R²:       {r2_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35987f80",
   "metadata": {},
   "source": [
    "### Save fitted pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8281da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fitted pipeline for reuse in inference\n",
    "joblib.dump(pipeline, pipeline_path)\n",
    "\n",
    "\n",
    "with open(os.path.join(artifacts_dir, \"metrics.txt\"), \"w\") as f:\n",
    "    f.write(f\"Training RMSE: {rmse_train:.6f}\\n\")\n",
    "    f.write(f\"Training R2:   {r2_train:.6f}\\n\")\n",
    "    f.write(f\"Test RMSE:     {rmse_test:.6f}\\n\")\n",
    "    f.write(f\"Test R2:       {r2_test:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d455b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
